{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87acf17c-29f9-4fae-8752-2d342f37ae97",
   "metadata": {},
   "source": [
    "This notebook runs a script for medication–diagnosis matching and first-line drug Identification using a Hugging Face LLM (DeepSeek-R1-Distill-Llama-8B).  \n",
    "\n",
    "It:\n",
    "- sets environment variables and logging,\n",
    "- loads the model/pipeline,\n",
    "- reads `patients.json`,\n",
    "- prompts the model to produce a strict **Markdown table** (Medication → Matched Diagnosis, Guideline Compliance, Citation, Notes, Optimisation Recommendation),\n",
    "- saves raw outputs, and\n",
    "- parses/saves **per-patient CSVs** for downstream analysis.\n",
    "\n",
    "> **Use case:** support for managing polypharmacy & multimorbidity (Structured Medication Review)\n",
    "> **Caveat:** LLM outputs should remain adjunctive to clinician judgment and authoritative guidelines (NICE/BNF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1464d6-7890-446f-a021-4421d445a46d",
   "metadata": {},
   "source": [
    "## 1) Environment, Imports, and Logging\n",
    "Turn off tokenizer parallelism warnings, import standard/third-party libraries, and configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd83c8-e960-427c-b3a8-71820439cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Import Standard library\n",
    "import time    # for measuring execution time\n",
    "import logging # for structured logging\n",
    "import json    # for reading/writing JSON files\n",
    "import re      # for regular expressions (text cleanup)\n",
    "\n",
    "# Import Third-party library (HuggingFace)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\") # timestamp, log level, message\n",
    "logger = logging.getLogger(__name__) # create logger for this script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a5ec6-0c2e-455b-8b37-2035f89c6169",
   "metadata": {},
   "source": [
    "## 2) Load Model and Build Text-Generation Pipeline\n",
    "Initialize DeepSeek-R1-Distill-Llama-8B on CPU and create the generation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404f7e93-9cad-4c83-928a-b6663bd43b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/DeepSeek-R1-Distill-Llama-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m      4\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Choose model\n",
    "MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# Load tokenizer (fast implementation enabled)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # pad with EOS token\n",
    "tokenizer.padding_side = \"right\"           # pad on the right side\n",
    "\n",
    "# Load model weights on CPU (can change to \"cuda\" if GPU available)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"cpu\")\n",
    "model.config.pad_token_id = tokenizer.eos_token_id  # align pad token id\n",
    "\n",
    "# Create HuggingFace text-generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",   # task type\n",
    "    model=model,\n",
    "    tokenizer=tokenizer, # running on CPU\n",
    "    device_map=\"cpu\",\n",
    "    framework=\"pt\"       # use PyTorch backend\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3355b-f927-441e-98c6-1b58dbd85d8f",
   "metadata": {},
   "source": [
    "## 3) Load Patients and Preview\n",
    "Read `patients.json` and print a compact list to verify inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987bd55-3635-493e-963d-9a8c78c4b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open patient data JSON file\n",
    "with open(\"patients.json\") as f:\n",
    "    patients = json.load(f)\n",
    "    \n",
    "# Display available patients for dictionary format\n",
    "for i, (patient_id, patient_info) in enumerate(patients.items()):\n",
    "    # Extract first diagnosis (before the first semicolon)\n",
    "    first_diagnosis = patient_info['diagnosis'].split(';')[0].strip()\n",
    "    # Print patient summary line\n",
    "    print(f\"{i+1}. {patient_info['patient_id']} - {patient_info['age']}yr {patient_info['sex']} - {first_diagnosis}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc8d28-6285-484b-ad0a-cd2aa78433df",
   "metadata": {},
   "source": [
    "## 4) Prompt Template (Few-Shot Prompt focused on BNF/NICE-Guideline)\n",
    "Instruction block requesting a strict Markdown table only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83f315-def6-4c9d-99bb-e3b0cd1104b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template instructing the model to act like a UK clinical pharmacist\n",
    "# Strictly enforce Markdown table output with fixed columns\n",
    "medication_diagnosis_prompt_template = \"\"\"\n",
    "You are a UK clinical pharmacist.\n",
    "\n",
    "Review the patient's medications and diagnoses.\n",
    "For each medication, determine which diagnosis it treats using BNF/NICE guideline only.\n",
    "If no diagnosis matches, write \"No matching diagnosis\".\n",
    "Also provide optimisation recommendations: identify drugs to continue, discontinue, dose-adjust, or switch.\n",
    "\n",
    "Output ONLY a markdown table with these exact columns:\n",
    "\n",
    "| Medication | Matched Diagnosis | Guideline Compliance | Citation | Notes | Optimisation Recommendation |\n",
    "|------------|-------------------|----------------------|----------|-------|---------------------------|\n",
    "\n",
    "Examples:\n",
    "Patient 1:\n",
    "Medications: Metformin; Atorvastatin; Lisinopril\n",
    "Diagnoses: Type 2 Diabetes; Dyslipidemia; Hypertension\n",
    "\n",
    "| Medication | Matched Diagnosis | Guideline Compliance | Citation | Notes | Optimisation Recommendation |\n",
    "|------------|-------------------|----------------------|----------|-------|---------------------------|\n",
    "| Metformin | Type 2 Diabetes | First-line | NICE NG28 | Standard first-line treatment | CONTINUE - appropriate first-line therapy |\n",
    "| Atorvastatin | Dyslipidemia | First-line | NICE CG181 | High-intensity statin | CONTINUE - achieving lipid targets |\n",
    "| Lisinopril | Hypertension | First-line | NICE NG136 | ACE inhibitor recommended | CONTINUE - well tolerated |\n",
    "\n",
    "Patient 2:\n",
    "Medications: Warfarin; Digoxin; Furosemide\n",
    "Diagnoses: Atrial Fibrillation; Heart Failure; Chronic Pain\n",
    "\n",
    "| Medication | Matched Diagnosis | Guideline Compliance | Citation | Notes | Optimisation Recommendation |\n",
    "|------------|-------------------|----------------------|----------|-------|---------------------------|\n",
    "| Warfarin | Atrial Fibrillation | First-line | NICE CG180 | Anticoagulation for stroke prevention | SWITCH - consider DOAC for convenience |\n",
    "| Digoxin | Heart Failure | Second-line | NICE NG106 | For symptom control in severe HF | CONTINUE - monitor levels |\n",
    "| Furosemide | Heart Failure | First-line | NICE NG106 | Loop diuretic for fluid management | DOSE-ADJUST - optimize based on symptoms |\n",
    "\n",
    "Now analyze this patient:\n",
    "Patient Data:\n",
    "Medications: {medications}\n",
    "Diagnoses: {diagnoses}\n",
    "\n",
    "Do not include any text before or after the table.\n",
    "Start your response with the table header line exactly as shown above.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40b37c-1f5b-4c5c-a029-5d0c8c7c934d",
   "metadata": {},
   "source": [
    "## 5) Helper Functions\n",
    "Format patient fields for the prompt and save raw outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada62395-bfd2-4de4-9986-6d0587b9e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_patient_data(patient):\n",
    "    \"\"\"Format patient medications and diagnoses for the prompt\"\"\"\n",
    "    medication_list = patient['medication'].split('; ')                                 # split string into list\n",
    "    medications = [re.sub(r\"\\s*\\(.*?\\)\", \"\", med).strip() for med in medication_list]   # remove parentheses and spaces\n",
    "    medications_str = \"; \".join(medications)                                            # join back with semicolons\n",
    "    diagnoses_str = patient['diagnosis']                                                # take diagnosis as-is\n",
    "    return medications_str, diagnoses_str\n",
    "\n",
    "def save_output(patient_id, output):\n",
    "    os.makedirs(\"results\", exist_ok=True)  # create folder if missing\n",
    "    with open(f\"results/{patient_id}_medication_diagnosis_result.txt\", \"w\") as f:\n",
    "        f.write(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed3df1-acda-42b7-93c3-e03d76a89c1b",
   "metadata": {},
   "source": [
    "## 6) Generate LLM Outputs for Each Patient\n",
    "Iterate through all patients, run the model, print, and save raw Markdown tables to `results/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd50cdc-bc5a-4858-9d5d-ad86d316e289",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patient_id, patient_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpatients\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     medications_str, diagnoses_str \u001b[38;5;241m=\u001b[39m format_patient_data(patient_data)\n\u001b[1;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m medication_diagnosis_prompt_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m      4\u001b[0m         medications\u001b[38;5;241m=\u001b[39mmedications_str,\n\u001b[1;32m      5\u001b[0m         diagnoses\u001b[38;5;241m=\u001b[39mdiagnoses_str\n\u001b[1;32m      6\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patients' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop through each patient and run clinical assessment\n",
    "for patient_id, patient_data in patients.items():\n",
    "    # Prepare patient-specific meds and diagnoses for the prompt\n",
    "    medications_str, diagnoses_str = format_patient_data(patient_data)\n",
    "    prompt = medication_diagnosis_prompt_template.format(\n",
    "        medications=medications_str,\n",
    "        diagnoses=diagnoses_str\n",
    "    )\n",
    "    logger.info(f\" Running medication-diagnosis matching for patient {patient_id}...\")\n",
    "    start = time.time() # track start time\n",
    "    raw_output = pipe(\n",
    "        prompt,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=1400,                 # token budget\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )[0][\"generated_text\"].strip()           # get text output and strip whitespace\n",
    "    duration = time.time() - start\n",
    "    logger.info(f\"✅ Completed for patient {patient_id} in {duration:.2f}s\")\n",
    "\n",
    "    # Print output to console\n",
    "    print(f\" Medication-Diagnosis Analysis for {patient_id}:\\n\")\n",
    "    print(raw_output)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Save raw output to file\n",
    "    save_output(patient_id, raw_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510bb51b-28ce-4824-a6ef-42de0535c4c3",
   "metadata": {},
   "source": [
    "## 7) Parse Model Output and Save CSVs\n",
    "Clean hallucinated tags, parse the Markdown table, and export per-patient CSVs to `results_csv/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f539d-0bfc-4a32-8480-f44079c9c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_raw_output(text):\n",
    "    # Remove hallucinated tags like </think> or similar\n",
    "    return re.sub(r\"</?\\w+>\", \"\", text).strip()\n",
    "\n",
    "def parse_markdown_table(text):\n",
    "    \"\"\"Parse the Markdown table into a list of dict rows.\"\"\"\n",
    "    rows = []\n",
    "    for line in text.strip().split(\"\\n\"):\n",
    "        if re.match(r\"\\|\\s*\\w+\", line) and not line.lower().startswith(\"| medication\"):\n",
    "            parts = [cell.strip() for cell in line.strip(\"|\").split(\"|\")]  # split columns\n",
    "            if len(parts) == 6:\n",
    "                rows.append({\n",
    "                    \"medication\": parts[0],\n",
    "                    \"matched_diagnosis\": parts[1],\n",
    "                    \"guideline_compliance\": parts[2],\n",
    "                    \"citation\": parts[3],\n",
    "                    \"notes\": parts[4],\n",
    "                    \"optimisation_recommendation\": parts[5]\n",
    "                })\n",
    "    return rows\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(\"results_csv\", exist_ok=True)\n",
    "\n",
    "# Loop through all result text files and generate CSVs\n",
    "for patient_id, patient_data in patients.items():\n",
    "    result_path = f\"results/{patient_id}_medication_diagnosis_result.txt\"\n",
    "    if not os.path.exists(result_path):\n",
    "        logger.warning(f\" Missing result file for {patient_id}, skipping.\")\n",
    "        continue\n",
    "        \n",
    "    with open(result_path, \"r\") as f:\n",
    "        raw_output = f.read()\n",
    "        \n",
    "    cleaned_output = clean_raw_output(raw_output)             # remove unwanted tags\n",
    "    structured_results = parse_markdown_table(cleaned_output) # parse Markdown\n",
    "    if structured_results:\n",
    "        df = pd.DataFrame(structured_results)                 # build DataFrame if valid rows exist\n",
    "    else:\n",
    "        # Ensure at least one row exists if \"No matching diagnosis found\"\n",
    "        df = pd.DataFrame([{\n",
    "            \"medication\": \"\",\n",
    "            \"matched_diagnosis\": \"\",\n",
    "            \"guideline_compliance\": \"\",\n",
    "            \"citation\": \"\",\n",
    "            \"notes\": \"No matching diagnosis found\",\n",
    "            \"optimisation_recommendation\": \"\"\n",
    "        }])\n",
    "    csv_path = f\"results_csv/{patient_id}_medication_diagnosis_structured.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    logger.info(f\"📁 Saved CSV for {patient_id} to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca611c-4e1d-46a7-9d61-f4e20ef7a45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a61bb048-a960-40fc-a568-402252f4b4eb",
   "metadata": {},
   "source": [
    "This code was used as part of **Olayemi Bakare's** MSc Research Work at Queen Mary University of London (Digital Environment and Innovation Lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bdace-f7a4-4501-8620-e2e41325f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fresh PyTorch Env",
   "language": "python",
   "name": "fresh_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
